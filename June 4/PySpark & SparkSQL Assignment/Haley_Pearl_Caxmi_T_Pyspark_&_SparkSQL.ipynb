{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "bEyXKSgDQH9i",
        "outputId": "8a0dad66-395e-4258-817a-d4102c32ea08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x77fec4a0db50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - hive</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c3ec446aa7f6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PracticeProject</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "spark =SparkSession.builder.appName(\"PracticeProject\").enableHiveSupport().getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Customers Data\n",
        "customers_data = [\n",
        "(101, 'Ali', 'ali@gmail.com', 'Mumbai', '2022-05-10'),\n",
        "(102, 'Neha', 'neha@yahoo.com', 'Delhi', '2023-01-15'),\n",
        "(103, 'Ravi', 'ravi@hotmail.com', 'Bangalore', '2021-11-01'),\n",
        "(104, 'Sneha', 'sneha@outlook.com', 'Hyderabad', '2020-07-22'),\n",
        "(105, 'Amit', 'amit@gmail.com', 'Chennai', '2023-03-10'),\n",
        "]"
      ],
      "metadata": {
        "id": "oA574GCxQxOY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_data = [\n",
        "(1, 101, 'Laptop', 'Electronics', 2, 50000.0, '2024-01-10'),\n",
        "(2, 101, 'Mouse', 'Electronics', 1, 1200.0, '2024-01-15'),\n",
        "(3, 102, 'Tablet', 'Electronics', 1, 20000.0, '2024-02-01'),\n",
        "(4, 103, 'Bookshelf', 'Furniture', 1, 3500.0, '2024-02-10'),\n",
        "(5, 104, 'Mixer', 'Appliances', 1, 5000.0, '2024-02-15'),\n",
        "(6, 105, 'Notebook', 'Stationery', 5, 500.0, '2024-03-01'),\n",
        "(7, 102, 'Phone', 'Electronics', 1, 30000.0, '2024-03-02'),\n",
        "]"
      ],
      "metadata": {
        "id": "EP6bcIdUQ1Fi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers_df = spark.createDataFrame(customers_data, [\"CustomerID\", \"Name\", \"Email\",\n",
        "\"City\", \"SignupDate\"])\n",
        "orders_df = spark.createDataFrame(orders_data, [\"OrderID\", \"CustomerID\", \"Product\",\n",
        "\"Category\", \"Quantity\", \"Price\", \"OrderDate\"])"
      ],
      "metadata": {
        "id": "UvXhRFOcQ3uh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS sales\")\n",
        "customers_df.write.mode(\"overwrite\").saveAsTable(\"sales.customers\")\n",
        "orders_df.write.mode(\"overwrite\").saveAsTable(\"sales.orders\")"
      ],
      "metadata": {
        "id": "C5Msq2VQSEIG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers_df.createOrReplaceTempView(\"customers\")\n",
        "orders_df.createOrReplaceTempView(\"orders\")\n"
      ],
      "metadata": {
        "id": "UJKE8TgtS9yY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM customers\").show()\n",
        "spark.sql(\"SELECT * FROM orders\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk1TwWtITSqD",
        "outputId": "693004c8-bdfb-4b31-efd2-fbec039a737b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|\n",
            "|       103| Ravi| ravi@hotmail.com|Bangalore|2021-11-01|\n",
            "|       104|Sneha|sneha@outlook.com|Hyderabad|2020-07-22|\n",
            "|       105| Amit|   amit@gmail.com|  Chennai|2023-03-10|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SECTION A: PySpark DataFrame Tasks\n",
        "# 1.Add TotalAmount column\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "orders_df = orders_df.withColumn(\"TotalAmount\", col(\"Price\") * col(\"Quantity\"))\n",
        "orders_df.select(\"OrderID\", \"Product\", \"Quantity\", \"Price\", \"TotalAmount\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKLj7jwdTf-8",
        "outputId": "e8c933e3-5bc0-4265-8b9f-b55c4dbbd630"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+--------+-------+-----------+\n",
            "|OrderID|  Product|Quantity|  Price|TotalAmount|\n",
            "+-------+---------+--------+-------+-----------+\n",
            "|      1|   Laptop|       2|50000.0|   100000.0|\n",
            "|      2|    Mouse|       1| 1200.0|     1200.0|\n",
            "|      3|   Tablet|       1|20000.0|    20000.0|\n",
            "|      4|Bookshelf|       1| 3500.0|     3500.0|\n",
            "|      5|    Mixer|       1| 5000.0|     5000.0|\n",
            "|      6| Notebook|       5|  500.0|     2500.0|\n",
            "|      7|    Phone|       1|30000.0|    30000.0|\n",
            "+-------+---------+--------+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.Filter orders with TotalAmount > 10000\n",
        "orders_df.filter(col(\"TotalAmount\") > 10000).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBirntxGVdRs",
        "outputId": "173fa035-f57b-488b-87b1-94147d559396"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+--------------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|AmountCategory|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+--------------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|          High|\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|        Medium|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|          High|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.Standardize City field (to lowercase)\n",
        "from pyspark.sql.functions import lower\n",
        "\n",
        "customers_df = customers_df.withColumn(\"City\", lower(col(\"City\")))\n",
        "customers_df.select(\"CustomerID\", \"Name\", \"City\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSBJqnyyVj3R",
        "outputId": "12c368cd-0728-47c4-b121-4aae1e9615e7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---------+\n",
            "|CustomerID| Name|     City|\n",
            "+----------+-----+---------+\n",
            "|       101|  Ali|   mumbai|\n",
            "|       102| Neha|    delhi|\n",
            "|       103| Ravi|bangalore|\n",
            "|       104|Sneha|hyderabad|\n",
            "|       105| Amit|  chennai|\n",
            "+----------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.Add OrderYear column\n",
        "from pyspark.sql.functions import year\n",
        "\n",
        "orders_df = orders_df.withColumn(\"OrderYear\", year(col(\"OrderDate\")))\n",
        "orders_df.select(\"OrderID\", \"OrderDate\", \"OrderYear\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLCPsXakVnXa",
        "outputId": "bc68e165-1242-42f4-d753-11d5a32c656c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+\n",
            "|OrderID| OrderDate|OrderYear|\n",
            "+-------+----------+---------+\n",
            "|      1|2024-01-10|     2024|\n",
            "|      2|2024-01-15|     2024|\n",
            "|      3|2024-02-01|     2024|\n",
            "|      4|2024-02-10|     2024|\n",
            "|      5|2024-02-15|     2024|\n",
            "|      6|2024-03-01|     2024|\n",
            "|      7|2024-03-02|     2024|\n",
            "+-------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.Fill null values in Email with a default value\n",
        "customers_df = customers_df.fillna({\"Email\": \"not_provided@example.com\"})\n",
        "customers_df.select(\"Name\", \"Email\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl48keruVr9I",
        "outputId": "5cb986dd-2914-48ce-b294-6716e0acc732"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "| Name|            Email|\n",
            "+-----+-----------------+\n",
            "|  Ali|    ali@gmail.com|\n",
            "| Neha|   neha@yahoo.com|\n",
            "| Ravi| ravi@hotmail.com|\n",
            "|Sneha|sneha@outlook.com|\n",
            "| Amit|   amit@gmail.com|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.Categorize orders as Low, Medium, High\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "orders_df = orders_df.withColumn(\n",
        "    \"AmountCategory\",\n",
        "    when(col(\"TotalAmount\") < 5000, \"Low\")\n",
        "    .when((col(\"TotalAmount\") >= 5000) & (col(\"TotalAmount\") <= 20000), \"Medium\")\n",
        "    .otherwise(\"High\")\n",
        ")\n",
        "orders_df.select(\"OrderID\", \"TotalAmount\", \"AmountCategory\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjA4TyG3WB_Q",
        "outputId": "d5bfcd83-30c4-44da-8987-7eb832fcc618"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+--------------+\n",
            "|OrderID|TotalAmount|AmountCategory|\n",
            "+-------+-----------+--------------+\n",
            "|      1|   100000.0|          High|\n",
            "|      2|     1200.0|           Low|\n",
            "|      3|    20000.0|        Medium|\n",
            "|      4|     3500.0|           Low|\n",
            "|      5|     5000.0|        Medium|\n",
            "|      6|     2500.0|           Low|\n",
            "|      7|    30000.0|          High|\n",
            "+-------+-----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SECTION B: Spark SQL Tasks\n",
        "# 7.Orders by Ali\n",
        "spark.sql(\"\"\"\n",
        "SELECT o.*\n",
        "FROM customers c\n",
        "JOIN orders o ON c.CustomerID = o.CustomerID\n",
        "WHERE c.Name = 'Ali'\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUsSBaPeWILQ",
        "outputId": "5450b859-b80a-48ab-be03-064381901c5a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|\n",
            "|      2|       101|  Mouse|Electronics|       1| 1200.0|2024-01-15|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.Total spending by each customer\n",
        "spark.sql(\"\"\"\n",
        "SELECT c.Name, SUM(o.TotalAmount) AS TotalSpending\n",
        "FROM customers c\n",
        "JOIN orders o ON c.CustomerID = o.CustomerID\n",
        "GROUP BY c.Name\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SciJxbZwXU3f",
        "outputId": "b28c7995-da6e-484a-83f8-92dd46b24fb3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------------+\n",
            "| Name|TotalSpending|\n",
            "+-----+-------------+\n",
            "| Ravi|       3500.0|\n",
            "|Sneha|       5000.0|\n",
            "| Amit|       2500.0|\n",
            "| Neha|      50000.0|\n",
            "|  Ali|     101200.0|\n",
            "+-----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.Category with highest total revenue\n",
        "spark.sql(\"\"\"\n",
        "SELECT Category, SUM(TotalAmount) AS Revenue\n",
        "FROM orders\n",
        "GROUP BY Category\n",
        "ORDER BY Revenue DESC\n",
        "LIMIT 1\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TX8ERulXbqO",
        "outputId": "6b1f7439-0973-46a4-a6c4-abd8d0d3d122"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+\n",
            "|   Category| Revenue|\n",
            "+-----------+--------+\n",
            "|Electronics|151200.0|\n",
            "+-----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.Create view customer_orders\n",
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE TEMP VIEW customer_orders AS\n",
        "SELECT c.Name AS CustomerName, o.Product, o.TotalAmount\n",
        "FROM customers c\n",
        "JOIN orders o ON c.CustomerID = o.CustomerID\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQhGQEcJXh8e",
        "outputId": "0a428f2a-9faa-4e23-e1a9-86a23cc9828c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11.Products ordered after Feb 2024\n",
        "spark.sql(\"\"\"\n",
        "SELECT *\n",
        "FROM customer_orders\n",
        "WHERE Product IN (\n",
        "    SELECT Product FROM orders WHERE OrderDate > '2024-02-01'\n",
        ")\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocn-FBqCXoNT",
        "outputId": "9d49c15d-cb4d-4c3d-8e32-bc75a2400f7b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------+-----------+\n",
            "|CustomerName|  Product|TotalAmount|\n",
            "+------------+---------+-----------+\n",
            "|        Neha|    Phone|    30000.0|\n",
            "|        Ravi|Bookshelf|     3500.0|\n",
            "|       Sneha|    Mixer|     5000.0|\n",
            "|        Amit| Notebook|     2500.0|\n",
            "+------------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SECTION C: Advanced Practice\n",
        "# 12.Global Temp View + Query\n",
        "customers_df.createOrReplaceGlobalTempView(\"customers\")\n",
        "spark.sql(\"SELECT * FROM global_temp.customers WHERE City = 'mumbai'\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CWqYiLWXuSF",
        "outputId": "b95b0b43-3dc9-4213-a4bb-e1fcc5ee663e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+-------------+------+----------+\n",
            "|CustomerID|Name|        Email|  City|SignupDate|\n",
            "+----------+----+-------------+------+----------+\n",
            "|       101| Ali|ali@gmail.com|mumbai|2022-05-10|\n",
            "+----------+----+-------------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13.Save to Parquet\n",
        "orders_df.write.mode(\"overwrite\").parquet(\"/content/orders_parquet\")\n"
      ],
      "metadata": {
        "id": "mZCrmsvoXzXq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14.Read Parquet & count\n",
        "orders_parquet = spark.read.parquet(\"/content/orders_parquet\")\n",
        "print(\"Total Orders:\", orders_parquet.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnIEGADiX3Kx",
        "outputId": "45a69627-e895-4a49-efed-ce4b9f139dfe"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Orders: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SECTION D: UDF + Built-in Function Tasks\n",
        "# 15.Mask email using UDF\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def mask_email(email):\n",
        "    parts = email.split(\"@\")\n",
        "    return parts[0][0] + \"***@\" + parts[1] if len(parts) == 2 else email\n",
        "\n",
        "mask_email_udf = udf(mask_email, StringType())\n",
        "\n",
        "customers_df = customers_df.withColumn(\"MaskedEmail\", mask_email_udf(col(\"Email\")))\n",
        "customers_df.select(\"Email\", \"MaskedEmail\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8-GxpywX7eq",
        "outputId": "99a9eff3-85b3-4dc8-8ee2-f2426ebd3c63"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+\n",
            "|            Email|     MaskedEmail|\n",
            "+-----------------+----------------+\n",
            "|    ali@gmail.com|  a***@gmail.com|\n",
            "|   neha@yahoo.com|  n***@yahoo.com|\n",
            "| ravi@hotmail.com|r***@hotmail.com|\n",
            "|sneha@outlook.com|s***@outlook.com|\n",
            "|   amit@gmail.com|  a***@gmail.com|\n",
            "+-----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16.Create label using concat_ws\n",
        "from pyspark.sql.functions import concat_ws\n",
        "\n",
        "customers_df = customers_df.withColumn(\"Label\", concat_ws(\" from \", col(\"Name\"), col(\"City\")))\n",
        "customers_df.select(\"Label\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "734RjJ57YEKK",
        "outputId": "4947b809-121b-4116-af5c-d8dcea52bd74"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               Label|\n",
            "+--------------------+\n",
            "|     Ali from mumbai|\n",
            "|     Neha from delhi|\n",
            "| Ravi from bangalore|\n",
            "|Sneha from hyderabad|\n",
            "|   Amit from chennai|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 17.Clean Product names\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "orders_df = orders_df.withColumn(\"CleanProduct\", regexp_replace(\"Product\", \"[^a-zA-Z0-9 ]\", \"\"))\n",
        "orders_df.select(\"Product\", \"CleanProduct\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dxdNplUYHtj",
        "outputId": "28b3c664-87a5-4090-cae1-a7f99220fd3c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+\n",
            "|  Product|CleanProduct|\n",
            "+---------+------------+\n",
            "|   Laptop|      Laptop|\n",
            "|    Mouse|       Mouse|\n",
            "|   Tablet|      Tablet|\n",
            "|Bookshelf|   Bookshelf|\n",
            "|    Mixer|       Mixer|\n",
            "| Notebook|    Notebook|\n",
            "|    Phone|       Phone|\n",
            "+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 18.Days since signup\n",
        "from pyspark.sql.functions import to_date, datediff, lit\n",
        "from datetime import date\n",
        "\n",
        "today_str = date.today().isoformat()\n",
        "customers_df = customers_df.withColumn(\"SignupDate\", to_date(\"SignupDate\"))\n",
        "customers_df = customers_df.withColumn(\"DaysSinceSignup\", datediff(lit(today_str), col(\"SignupDate\")))\n",
        "customers_df.select(\"Name\", \"SignupDate\", \"DaysSinceSignup\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv0r4pxqYL3h",
        "outputId": "238bc62c-5b90-4bf9-d3da-f03d7e8e134d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+---------------+\n",
            "| Name|SignupDate|DaysSinceSignup|\n",
            "+-----+----------+---------------+\n",
            "|  Ali|2022-05-10|           1121|\n",
            "| Neha|2023-01-15|            871|\n",
            "| Ravi|2021-11-01|           1311|\n",
            "|Sneha|2020-07-22|           1778|\n",
            "| Amit|2023-03-10|            817|\n",
            "+-----+----------+---------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}