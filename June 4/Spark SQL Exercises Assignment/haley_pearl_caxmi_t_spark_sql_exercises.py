# -*- coding: utf-8 -*-
"""Haley Pearl Caxmi T-Spark SQL Exercises.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KwXAhyYpRnIvxjXGP3wMOql-vl7Nuy8x
"""

from pyspark.sql import SparkSession

spark=SparkSession.builder.appName("SQL Exercises").getOrCreate()

spark

#1. Create a new database
spark.sql("CREATE DATABASE IF NOT EXISTS sales_db")

#2. Set current database
spark.sql("USE sales_db")

#3. Create product_sales table
spark.sql("""
CREATE TABLE IF NOT EXISTS product_sales (
    ProductID INT,
    ProductName STRING,
    Category STRING,
    Price DOUBLE,
    Quantity INT,
    SaleDate DATE
)
USING PARQUET
""")

#4. Insert 5 rows into product_sales
spark.sql("INSERT INTO product_sales VALUES (1, 'Laptop', 'Electronics', 55000, 2, DATE('2024-01-12'))")
spark.sql("INSERT INTO product_sales VALUES (2, 'Mouse', 'Electronics', 800, 5, DATE('2024-01-13'))")
spark.sql("INSERT INTO product_sales VALUES (3, 'Shirt', 'Fashion', 1200, 3, DATE('2024-02-01'))")
spark.sql("INSERT INTO product_sales VALUES (4, 'Book', 'Books', 500, 4, DATE('2024-02-15'))")
spark.sql("INSERT INTO product_sales VALUES (5, 'Chair', 'Furniture', 2000, 1, DATE('2024-03-10'))")

#5. Select all records
spark.sql("SELECT * FROM product_sales").show()

#6. Products with price > 500
spark.sql("SELECT * FROM product_sales WHERE Price > 500").show()

#7. Total sale amount for each product
spark.sql("SELECT ProductName, Price * Quantity AS TotalSale FROM product_sales").show()

#8. Count of products sold per category
spark.sql("SELECT Category, SUM(Quantity) AS TotalSold FROM product_sales GROUP BY Category").show()

#9. Sort by total sales descending
spark.sql("SELECT ProductName, Price * Quantity AS TotalSale FROM product_sales ORDER BY TotalSale DESC").show()

#10. Create dummy DataFrame
from pyspark.sql import Row

temp_data = [
    Row(ProductID=101, ProductName="Tablet", Quantity=1),
    Row(ProductID=102, ProductName="Headphones", Quantity=3)
]

df_temp = spark.createDataFrame(temp_data)

#11. Register as temp view
df_temp.createOrReplaceTempView("temp_orders")

#12. SQL query: quantity > 1
spark.sql("SELECT * FROM temp_orders WHERE Quantity > 1").show()

#13. Create global temp view
df_temp.createOrReplaceGlobalTempView("global_orders")

#14. Query from another cell/session
spark.sql("SELECT * FROM global_temp.global_orders").show()

#15. Create customer_details table
spark.sql("""
CREATE TABLE IF NOT EXISTS customer_details (
    CustomerID INT,
    Name STRING,
    Gender STRING,
    City STRING,
    SignupDate DATE
)
USING PARQUET
""")

#16. Insert 3 records
spark.sql("INSERT INTO customer_details VALUES (1, 'Ali', 'Male', 'Hyderabad', DATE('2022-05-10'))")
spark.sql("INSERT INTO customer_details VALUES (2, 'Neha', 'Female', 'Mumbai', DATE('2023-01-15'))")
spark.sql("INSERT INTO customer_details VALUES (3, 'Ravi', 'Male', 'Delhi', DATE('2021-12-01'))")

#17. Join (simulate match with ProductID = CustomerID)
spark.sql("""
SELECT p.ProductID, p.ProductName, c.Name, c.City
FROM product_sales p
JOIN customer_details c
ON p.ProductID = c.CustomerID
""").show()

#18. Customers who bought more than 2 products
spark.sql("""
SELECT c.Name, SUM(p.Quantity) AS TotalPurchased
FROM product_sales p
JOIN customer_details c
ON p.ProductID = c.CustomerID
GROUP BY c.Name
HAVING TotalPurchased > 2
""").show()

#19. Create sales_summary view
spark.sql("""
CREATE OR REPLACE VIEW sales_summary AS
SELECT ProductName, Price, Quantity, (Price * Quantity) AS Total
FROM product_sales
""")

#20. Query sales_summary where Total > 1000
spark.sql("SELECT * FROM sales_summary WHERE Total > 1000").show()

#21. Drop the view
spark.sql("DROP VIEW IF EXISTS sales_summary")

#22. Drop both tables
spark.sql("DROP TABLE IF EXISTS product_sales")
spark.sql("DROP TABLE IF EXISTS customer_details")

#23. Drop the database
spark.sql("DROP DATABASE IF EXISTS sales_db CASCADE")